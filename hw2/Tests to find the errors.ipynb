{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edoardocetin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/edoardocetin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import logz\n",
    "import scipy.signal\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "\t\tinput_placeholder, \n",
    "\t\toutput_size,\n",
    "\t\tscope, \n",
    "\t\tn_layers=2, \n",
    "\t\tsize=64, \n",
    "\t\tactivation=tf.tanh,\n",
    "\t\toutput_activation=None\n",
    "\t\t):\n",
    "\t#========================================================================================#\n",
    "\t#                           ----------SECTION 3----------\n",
    "\t# Network building\n",
    "\t#\n",
    "\t# Your code should make a feedforward neural network (also called a multilayer perceptron)\n",
    "\t# with 'n_layers' hidden layers of size 'size' units. \n",
    "\t# \n",
    "\t# The output layer should have size 'output_size' and activation 'output_activation'.\n",
    "\t#\n",
    "\t# Hint: use tf.layers.dense\n",
    "\t#========================================================================================#\n",
    "\n",
    "\twith tf.variable_scope(scope):\n",
    "\t\t# YOUR_CODE_HERE\n",
    "\t\tout = tf.layers.dense(input_placeholder, size, activation=activation, name=\"fcfirst\")\n",
    "\t\tfor i in range(n_layers - 2):\n",
    "\t\t\tout = tf.layers.dense(out, size, activation=activation, name = \"fc\" + str(i+1))\n",
    "\t\tout = tf.layers.dense(out, output_size, activation=output_activation, name = \"fclast\")\n",
    "\t\treturn out\n",
    "def pathlength(path):\n",
    "\treturn len(path[\"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "True\n",
      "********** Iteration 0 ************\n",
      "----------------------------------------\n",
      "|               Time |            1.41 |\n",
      "|          Iteration |               0 |\n",
      "|      AverageReturn |            30.7 |\n",
      "|          StdReturn |            19.3 |\n",
      "|          MaxReturn |             127 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            30.7 |\n",
      "|           EpLenStd |            19.3 |\n",
      "| TimestepsThisBatch |        5.00e+03 |\n",
      "|     TimestepsSoFar |        5.00e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "----------------------------------------\n",
      "|               Time |            2.46 |\n",
      "|          Iteration |               1 |\n",
      "|      AverageReturn |              34 |\n",
      "|          StdReturn |            17.8 |\n",
      "|          MaxReturn |             122 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |              34 |\n",
      "|           EpLenStd |            17.8 |\n",
      "| TimestepsThisBatch |        5.07e+03 |\n",
      "|     TimestepsSoFar |        1.01e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "----------------------------------------\n",
      "|               Time |            3.51 |\n",
      "|          Iteration |               2 |\n",
      "|      AverageReturn |            34.3 |\n",
      "|          StdReturn |            17.9 |\n",
      "|          MaxReturn |              98 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            34.3 |\n",
      "|           EpLenStd |            17.9 |\n",
      "| TimestepsThisBatch |        5.01e+03 |\n",
      "|     TimestepsSoFar |        1.51e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "----------------------------------------\n",
      "|               Time |            4.65 |\n",
      "|          Iteration |               3 |\n",
      "|      AverageReturn |            36.1 |\n",
      "|          StdReturn |            17.7 |\n",
      "|          MaxReturn |             108 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            36.1 |\n",
      "|           EpLenStd |            17.7 |\n",
      "| TimestepsThisBatch |        5.01e+03 |\n",
      "|     TimestepsSoFar |        2.01e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "----------------------------------------\n",
      "|               Time |            5.76 |\n",
      "|          Iteration |               4 |\n",
      "|      AverageReturn |            40.1 |\n",
      "|          StdReturn |              21 |\n",
      "|          MaxReturn |             105 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            40.1 |\n",
      "|           EpLenStd |              21 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        2.51e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "----------------------------------------\n",
      "|               Time |            6.81 |\n",
      "|          Iteration |               5 |\n",
      "|      AverageReturn |              41 |\n",
      "|          StdReturn |            21.2 |\n",
      "|          MaxReturn |             153 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |              41 |\n",
      "|           EpLenStd |            21.2 |\n",
      "| TimestepsThisBatch |        5.01e+03 |\n",
      "|     TimestepsSoFar |        3.01e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "----------------------------------------\n",
      "|               Time |            7.89 |\n",
      "|          Iteration |               6 |\n",
      "|      AverageReturn |            45.5 |\n",
      "|          StdReturn |            28.3 |\n",
      "|          MaxReturn |             170 |\n",
      "|          MinReturn |              14 |\n",
      "|          EpLenMean |            45.5 |\n",
      "|           EpLenStd |            28.3 |\n",
      "| TimestepsThisBatch |           5e+03 |\n",
      "|     TimestepsSoFar |        3.51e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "----------------------------------------\n",
      "|               Time |            8.93 |\n",
      "|          Iteration |               7 |\n",
      "|      AverageReturn |            47.3 |\n",
      "|          StdReturn |            25.4 |\n",
      "|          MaxReturn |             177 |\n",
      "|          MinReturn |              17 |\n",
      "|          EpLenMean |            47.3 |\n",
      "|           EpLenStd |            25.4 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        4.01e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "----------------------------------------\n",
      "|               Time |              10 |\n",
      "|          Iteration |               8 |\n",
      "|      AverageReturn |            46.9 |\n",
      "|          StdReturn |            25.1 |\n",
      "|          MaxReturn |             146 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |            46.9 |\n",
      "|           EpLenStd |            25.1 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        4.52e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "----------------------------------------\n",
      "|               Time |            11.2 |\n",
      "|          Iteration |               9 |\n",
      "|      AverageReturn |            47.8 |\n",
      "|          StdReturn |            24.2 |\n",
      "|          MaxReturn |             165 |\n",
      "|          MinReturn |              15 |\n",
      "|          EpLenMean |            47.8 |\n",
      "|           EpLenStd |            24.2 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        5.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 10 ************\n",
      "----------------------------------------\n",
      "|               Time |            12.3 |\n",
      "|          Iteration |              10 |\n",
      "|      AverageReturn |            50.1 |\n",
      "|          StdReturn |            26.9 |\n",
      "|          MaxReturn |             184 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |            50.1 |\n",
      "|           EpLenStd |            26.9 |\n",
      "| TimestepsThisBatch |        5.01e+03 |\n",
      "|     TimestepsSoFar |        5.52e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 11 ************\n",
      "----------------------------------------\n",
      "|               Time |            13.4 |\n",
      "|          Iteration |              11 |\n",
      "|      AverageReturn |            55.2 |\n",
      "|          StdReturn |            21.8 |\n",
      "|          MaxReturn |             123 |\n",
      "|          MinReturn |              18 |\n",
      "|          EpLenMean |            55.2 |\n",
      "|           EpLenStd |            21.8 |\n",
      "| TimestepsThisBatch |        5.03e+03 |\n",
      "|     TimestepsSoFar |        6.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 12 ************\n",
      "----------------------------------------\n",
      "|               Time |            14.5 |\n",
      "|          Iteration |              12 |\n",
      "|      AverageReturn |            56.5 |\n",
      "|          StdReturn |            28.9 |\n",
      "|          MaxReturn |             134 |\n",
      "|          MinReturn |              16 |\n",
      "|          EpLenMean |            56.5 |\n",
      "|           EpLenStd |            28.9 |\n",
      "| TimestepsThisBatch |        5.03e+03 |\n",
      "|     TimestepsSoFar |        6.52e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 13 ************\n",
      "----------------------------------------\n",
      "|               Time |            15.6 |\n",
      "|          Iteration |              13 |\n",
      "|      AverageReturn |            51.6 |\n",
      "|          StdReturn |              23 |\n",
      "|          MaxReturn |             168 |\n",
      "|          MinReturn |              20 |\n",
      "|          EpLenMean |            51.6 |\n",
      "|           EpLenStd |              23 |\n",
      "| TimestepsThisBatch |        5.01e+03 |\n",
      "|     TimestepsSoFar |        7.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 14 ************\n",
      "----------------------------------------\n",
      "|               Time |            16.7 |\n",
      "|          Iteration |              14 |\n",
      "|      AverageReturn |            54.3 |\n",
      "|          StdReturn |            28.9 |\n",
      "|          MaxReturn |             194 |\n",
      "|          MinReturn |              14 |\n",
      "|          EpLenMean |            54.3 |\n",
      "|           EpLenStd |            28.9 |\n",
      "| TimestepsThisBatch |        5.05e+03 |\n",
      "|     TimestepsSoFar |        7.53e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 15 ************\n",
      "----------------------------------------\n",
      "|               Time |            17.8 |\n",
      "|          Iteration |              15 |\n",
      "|      AverageReturn |            63.8 |\n",
      "|          StdReturn |            32.3 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              24 |\n",
      "|          EpLenMean |            63.8 |\n",
      "|           EpLenStd |            32.3 |\n",
      "| TimestepsThisBatch |        5.04e+03 |\n",
      "|     TimestepsSoFar |        8.03e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 16 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            18.9 |\n",
      "|          Iteration |              16 |\n",
      "|      AverageReturn |              61 |\n",
      "|          StdReturn |            30.5 |\n",
      "|          MaxReturn |             140 |\n",
      "|          MinReturn |              18 |\n",
      "|          EpLenMean |              61 |\n",
      "|           EpLenStd |            30.5 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        8.54e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 17 ************\n",
      "----------------------------------------\n",
      "|               Time |              20 |\n",
      "|          Iteration |              17 |\n",
      "|      AverageReturn |            65.8 |\n",
      "|          StdReturn |            25.4 |\n",
      "|          MaxReturn |             140 |\n",
      "|          MinReturn |              20 |\n",
      "|          EpLenMean |            65.8 |\n",
      "|           EpLenStd |            25.4 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        9.05e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 18 ************\n",
      "----------------------------------------\n",
      "|               Time |              21 |\n",
      "|          Iteration |              18 |\n",
      "|      AverageReturn |            64.2 |\n",
      "|          StdReturn |            32.7 |\n",
      "|          MaxReturn |             180 |\n",
      "|          MinReturn |              19 |\n",
      "|          EpLenMean |            64.2 |\n",
      "|           EpLenStd |            32.7 |\n",
      "| TimestepsThisBatch |        5.00e+03 |\n",
      "|     TimestepsSoFar |        9.55e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 19 ************\n",
      "----------------------------------------\n",
      "|               Time |            22.1 |\n",
      "|          Iteration |              19 |\n",
      "|      AverageReturn |            69.1 |\n",
      "|          StdReturn |            35.9 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              25 |\n",
      "|          EpLenMean |            69.1 |\n",
      "|           EpLenStd |            35.9 |\n",
      "| TimestepsThisBatch |        5.12e+03 |\n",
      "|     TimestepsSoFar |        1.01e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 20 ************\n",
      "----------------------------------------\n",
      "|               Time |            23.2 |\n",
      "|          Iteration |              20 |\n",
      "|      AverageReturn |            68.2 |\n",
      "|          StdReturn |            35.6 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              19 |\n",
      "|          EpLenMean |            68.2 |\n",
      "|           EpLenStd |            35.6 |\n",
      "| TimestepsThisBatch |        5.05e+03 |\n",
      "|     TimestepsSoFar |        1.06e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 21 ************\n",
      "----------------------------------------\n",
      "|               Time |            24.3 |\n",
      "|          Iteration |              21 |\n",
      "|      AverageReturn |            85.5 |\n",
      "|          StdReturn |            35.6 |\n",
      "|          MaxReturn |             184 |\n",
      "|          MinReturn |              34 |\n",
      "|          EpLenMean |            85.5 |\n",
      "|           EpLenStd |            35.6 |\n",
      "| TimestepsThisBatch |        5.05e+03 |\n",
      "|     TimestepsSoFar |        1.11e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 22 ************\n",
      "----------------------------------------\n",
      "|               Time |            25.4 |\n",
      "|          Iteration |              22 |\n",
      "|      AverageReturn |              88 |\n",
      "|          StdReturn |            42.3 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              18 |\n",
      "|          EpLenMean |              88 |\n",
      "|           EpLenStd |            42.3 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        1.16e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 23 ************\n",
      "----------------------------------------\n",
      "|               Time |            26.5 |\n",
      "|          Iteration |              23 |\n",
      "|      AverageReturn |            89.4 |\n",
      "|          StdReturn |            37.1 |\n",
      "|          MaxReturn |             189 |\n",
      "|          MinReturn |              25 |\n",
      "|          EpLenMean |            89.4 |\n",
      "|           EpLenStd |            37.1 |\n",
      "| TimestepsThisBatch |        5.09e+03 |\n",
      "|     TimestepsSoFar |        1.21e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 24 ************\n",
      "----------------------------------------\n",
      "|               Time |            27.6 |\n",
      "|          Iteration |              24 |\n",
      "|      AverageReturn |            91.2 |\n",
      "|          StdReturn |            42.7 |\n",
      "|          MaxReturn |             189 |\n",
      "|          MinReturn |              23 |\n",
      "|          EpLenMean |            91.2 |\n",
      "|           EpLenStd |            42.7 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        1.26e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 25 ************\n",
      "----------------------------------------\n",
      "|               Time |            28.7 |\n",
      "|          Iteration |              25 |\n",
      "|      AverageReturn |             101 |\n",
      "|          StdReturn |            47.8 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              28 |\n",
      "|          EpLenMean |             101 |\n",
      "|           EpLenStd |            47.8 |\n",
      "| TimestepsThisBatch |        5.07e+03 |\n",
      "|     TimestepsSoFar |        1.31e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 26 ************\n",
      "----------------------------------------\n",
      "|               Time |            29.8 |\n",
      "|          Iteration |              26 |\n",
      "|      AverageReturn |             117 |\n",
      "|          StdReturn |            42.2 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              33 |\n",
      "|          EpLenMean |             117 |\n",
      "|           EpLenStd |            42.2 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        1.36e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 27 ************\n",
      "----------------------------------------\n",
      "|               Time |            30.9 |\n",
      "|          Iteration |              27 |\n",
      "|      AverageReturn |             105 |\n",
      "|          StdReturn |              47 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              31 |\n",
      "|          EpLenMean |             105 |\n",
      "|           EpLenStd |              47 |\n",
      "| TimestepsThisBatch |        5.15e+03 |\n",
      "|     TimestepsSoFar |        1.41e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 28 ************\n",
      "----------------------------------------\n",
      "|               Time |              32 |\n",
      "|          Iteration |              28 |\n",
      "|      AverageReturn |             125 |\n",
      "|          StdReturn |            50.7 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              25 |\n",
      "|          EpLenMean |             125 |\n",
      "|           EpLenStd |            50.7 |\n",
      "| TimestepsThisBatch |        5.13e+03 |\n",
      "|     TimestepsSoFar |        1.46e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 29 ************\n",
      "----------------------------------------\n",
      "|               Time |              33 |\n",
      "|          Iteration |              29 |\n",
      "|      AverageReturn |             119 |\n",
      "|          StdReturn |            38.5 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              29 |\n",
      "|          EpLenMean |             119 |\n",
      "|           EpLenStd |            38.5 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        1.51e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 30 ************\n",
      "----------------------------------------\n",
      "|               Time |            34.1 |\n",
      "|          Iteration |              30 |\n",
      "|      AverageReturn |             130 |\n",
      "|          StdReturn |            40.5 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              25 |\n",
      "|          EpLenMean |             130 |\n",
      "|           EpLenStd |            40.5 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        1.56e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 31 ************\n",
      "----------------------------------------\n",
      "|               Time |            35.2 |\n",
      "|          Iteration |              31 |\n",
      "|      AverageReturn |             132 |\n",
      "|          StdReturn |            46.5 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              33 |\n",
      "|          EpLenMean |             132 |\n",
      "|           EpLenStd |            46.5 |\n",
      "| TimestepsThisBatch |        5.02e+03 |\n",
      "|     TimestepsSoFar |        1.61e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 32 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            36.3 |\n",
      "|          Iteration |              32 |\n",
      "|      AverageReturn |             125 |\n",
      "|          StdReturn |            45.6 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              39 |\n",
      "|          EpLenMean |             125 |\n",
      "|           EpLenStd |            45.6 |\n",
      "| TimestepsThisBatch |        5.11e+03 |\n",
      "|     TimestepsSoFar |        1.66e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 33 ************\n",
      "----------------------------------------\n",
      "|               Time |            37.4 |\n",
      "|          Iteration |              33 |\n",
      "|      AverageReturn |             133 |\n",
      "|          StdReturn |            41.9 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              26 |\n",
      "|          EpLenMean |             133 |\n",
      "|           EpLenStd |            41.9 |\n",
      "| TimestepsThisBatch |        5.07e+03 |\n",
      "|     TimestepsSoFar |        1.71e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 34 ************\n",
      "----------------------------------------\n",
      "|               Time |            38.5 |\n",
      "|          Iteration |              34 |\n",
      "|      AverageReturn |             143 |\n",
      "|          StdReturn |            51.1 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              25 |\n",
      "|          EpLenMean |             143 |\n",
      "|           EpLenStd |            51.1 |\n",
      "| TimestepsThisBatch |        5.16e+03 |\n",
      "|     TimestepsSoFar |        1.77e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 35 ************\n",
      "----------------------------------------\n",
      "|               Time |            39.6 |\n",
      "|          Iteration |              35 |\n",
      "|      AverageReturn |             133 |\n",
      "|          StdReturn |            42.4 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              55 |\n",
      "|          EpLenMean |             133 |\n",
      "|           EpLenStd |            42.4 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        1.82e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 36 ************\n",
      "----------------------------------------\n",
      "|               Time |            40.7 |\n",
      "|          Iteration |              36 |\n",
      "|      AverageReturn |             149 |\n",
      "|          StdReturn |            44.5 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              39 |\n",
      "|          EpLenMean |             149 |\n",
      "|           EpLenStd |            44.5 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        1.87e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 37 ************\n",
      "----------------------------------------\n",
      "|               Time |            41.9 |\n",
      "|          Iteration |              37 |\n",
      "|      AverageReturn |             156 |\n",
      "|          StdReturn |            46.1 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              39 |\n",
      "|          EpLenMean |             156 |\n",
      "|           EpLenStd |            46.1 |\n",
      "| TimestepsThisBatch |           5e+03 |\n",
      "|     TimestepsSoFar |        1.92e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 38 ************\n",
      "----------------------------------------\n",
      "|               Time |              43 |\n",
      "|          Iteration |              38 |\n",
      "|      AverageReturn |             158 |\n",
      "|          StdReturn |            46.2 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              57 |\n",
      "|          EpLenMean |             158 |\n",
      "|           EpLenStd |            46.2 |\n",
      "| TimestepsThisBatch |         5.2e+03 |\n",
      "|     TimestepsSoFar |        1.97e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 39 ************\n",
      "----------------------------------------\n",
      "|               Time |            44.1 |\n",
      "|          Iteration |              39 |\n",
      "|      AverageReturn |             182 |\n",
      "|          StdReturn |            25.9 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             121 |\n",
      "|          EpLenMean |             182 |\n",
      "|           EpLenStd |            25.9 |\n",
      "| TimestepsThisBatch |        5.11e+03 |\n",
      "|     TimestepsSoFar |        2.02e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 40 ************\n",
      "----------------------------------------\n",
      "|               Time |            45.3 |\n",
      "|          Iteration |              40 |\n",
      "|      AverageReturn |             173 |\n",
      "|          StdReturn |              38 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              85 |\n",
      "|          EpLenMean |             173 |\n",
      "|           EpLenStd |              38 |\n",
      "| TimestepsThisBatch |         5.2e+03 |\n",
      "|     TimestepsSoFar |        2.07e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 41 ************\n",
      "----------------------------------------\n",
      "|               Time |            46.3 |\n",
      "|          Iteration |              41 |\n",
      "|      AverageReturn |             169 |\n",
      "|          StdReturn |            36.9 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              81 |\n",
      "|          EpLenMean |             169 |\n",
      "|           EpLenStd |            36.9 |\n",
      "| TimestepsThisBatch |        5.06e+03 |\n",
      "|     TimestepsSoFar |        2.12e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 42 ************\n",
      "----------------------------------------\n",
      "|               Time |            47.4 |\n",
      "|          Iteration |              42 |\n",
      "|      AverageReturn |             173 |\n",
      "|          StdReturn |            40.9 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              34 |\n",
      "|          EpLenMean |             173 |\n",
      "|           EpLenStd |            40.9 |\n",
      "| TimestepsThisBatch |        5.03e+03 |\n",
      "|     TimestepsSoFar |        2.17e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 43 ************\n",
      "----------------------------------------\n",
      "|               Time |            48.5 |\n",
      "|          Iteration |              43 |\n",
      "|      AverageReturn |             190 |\n",
      "|          StdReturn |            25.4 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              80 |\n",
      "|          EpLenMean |             190 |\n",
      "|           EpLenStd |            25.4 |\n",
      "| TimestepsThisBatch |        5.14e+03 |\n",
      "|     TimestepsSoFar |        2.22e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 44 ************\n",
      "----------------------------------------\n",
      "|               Time |            49.6 |\n",
      "|          Iteration |              44 |\n",
      "|      AverageReturn |             191 |\n",
      "|          StdReturn |            16.8 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             140 |\n",
      "|          EpLenMean |             191 |\n",
      "|           EpLenStd |            16.8 |\n",
      "| TimestepsThisBatch |        5.15e+03 |\n",
      "|     TimestepsSoFar |        2.28e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 45 ************\n",
      "----------------------------------------\n",
      "|               Time |            50.7 |\n",
      "|          Iteration |              45 |\n",
      "|      AverageReturn |             194 |\n",
      "|          StdReturn |            19.6 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             104 |\n",
      "|          EpLenMean |             194 |\n",
      "|           EpLenStd |            19.6 |\n",
      "| TimestepsThisBatch |        5.03e+03 |\n",
      "|     TimestepsSoFar |        2.33e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 46 ************\n",
      "----------------------------------------\n",
      "|               Time |            51.7 |\n",
      "|          Iteration |              46 |\n",
      "|      AverageReturn |             188 |\n",
      "|          StdReturn |            19.1 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             122 |\n",
      "|          EpLenMean |             188 |\n",
      "|           EpLenStd |            19.1 |\n",
      "| TimestepsThisBatch |        5.07e+03 |\n",
      "|     TimestepsSoFar |        2.38e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 47 ************\n",
      "----------------------------------------\n",
      "|               Time |            52.9 |\n",
      "|          Iteration |              47 |\n",
      "|      AverageReturn |             188 |\n",
      "|          StdReturn |            21.2 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             128 |\n",
      "|          EpLenMean |             188 |\n",
      "|           EpLenStd |            21.2 |\n",
      "| TimestepsThisBatch |        5.08e+03 |\n",
      "|     TimestepsSoFar |        2.43e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 48 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            53.9 |\n",
      "|          Iteration |              48 |\n",
      "|      AverageReturn |             189 |\n",
      "|          StdReturn |            23.8 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              83 |\n",
      "|          EpLenMean |             189 |\n",
      "|           EpLenStd |            23.8 |\n",
      "| TimestepsThisBatch |        5.11e+03 |\n",
      "|     TimestepsSoFar |        2.48e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 49 ************\n",
      "----------------------------------------\n",
      "|               Time |              55 |\n",
      "|          Iteration |              49 |\n",
      "|      AverageReturn |             192 |\n",
      "|          StdReturn |            21.4 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              99 |\n",
      "|          EpLenMean |             192 |\n",
      "|           EpLenStd |            21.4 |\n",
      "| TimestepsThisBatch |           5e+03 |\n",
      "|     TimestepsSoFar |        2.53e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 50 ************\n",
      "----------------------------------------\n",
      "|               Time |            56.1 |\n",
      "|          Iteration |              50 |\n",
      "|      AverageReturn |             198 |\n",
      "|          StdReturn |            8.27 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             157 |\n",
      "|          EpLenMean |             198 |\n",
      "|           EpLenStd |            8.27 |\n",
      "| TimestepsThisBatch |        5.16e+03 |\n",
      "|     TimestepsSoFar |        2.58e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 51 ************\n",
      "----------------------------------------\n",
      "|               Time |            57.2 |\n",
      "|          Iteration |              51 |\n",
      "|      AverageReturn |             198 |\n",
      "|          StdReturn |            8.46 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             156 |\n",
      "|          EpLenMean |             198 |\n",
      "|           EpLenStd |            8.46 |\n",
      "| TimestepsThisBatch |        5.16e+03 |\n",
      "|     TimestepsSoFar |        2.63e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 52 ************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edoardocetin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:329: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            58.4 |\n",
      "|          Iteration |              52 |\n",
      "|      AverageReturn |             200 |\n",
      "|          StdReturn |               0 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |             200 |\n",
      "|          EpLenMean |             200 |\n",
      "|           EpLenStd |               0 |\n",
      "| TimestepsThisBatch |         5.2e+03 |\n",
      "|     TimestepsSoFar |        2.68e+05 |\n",
      "----------------------------------------\n",
      "********** Iteration 53 ************\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "2 (<class 'numpy.int64'>) invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d9d46992dfab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0macs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 2 (<class 'numpy.int64'>) invalid"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "exp_name=''\n",
    "env_name='InvertedPendulum-v1'\n",
    "n_iter=100 \n",
    "gamma=1.0\n",
    "min_timesteps_per_batch=5000\n",
    "max_path_length=None\n",
    "learning_rate=5e-3 \n",
    "reward_to_go=False\n",
    "animate=False\n",
    "logdir=None \n",
    "normalize_advantages=True\n",
    "nn_baseline=False\n",
    "seed=0\n",
    "# network arguments\n",
    "n_layers=1\n",
    "size=32\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Configure output directory for logging\n",
    "\"\"\"\n",
    "logz.configure_output_dir(logdir)\n",
    "\n",
    "# Log experimental parameters\n",
    "args = inspect.getargspec(train_PG)[0]\n",
    "locals_ = locals()\n",
    "params = {k: locals_[k] if k in locals_ else None for k in args}\n",
    "logz.save_params(params)\n",
    "\n",
    "# Set random seeds\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\"\"\"\n",
    "# Make the gym environment\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# Is this env continuous, or discrete?\n",
    "discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "print(discrete)\n",
    "\n",
    "# Maximum length for episodes\n",
    "max_path_length = max_path_length or env.spec.max_episode_steps\n",
    "\n",
    "#========================================================================================#\n",
    "# Notes on notation:\n",
    "# \n",
    "# Symbolic variables have the prefix sy_, to distinguish them from the numerical values\n",
    "# that are computed later in the function\n",
    "# \n",
    "# Prefixes and suffixes:\n",
    "# ob - observation \n",
    "# ac - action\n",
    "# _no - this tensor should have shape (batch size /n/, observation dim)\n",
    "# _na - this tensor should have shape (batch size /n/, action dim)\n",
    "# _n  - this tensor should have shape (batch size /n/)\n",
    "# \n",
    "# Note: batch size /n/ is defined at runtime, and until then, the shape for that axis\n",
    "# is None\n",
    "#========================================================================================#\n",
    "\n",
    "# Observation and action sizes\n",
    "ob_dim = env.observation_space.shape[0]\n",
    "ac_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "#========================================================================================#\n",
    "#                           ----------SECTION 4----------\n",
    "# Placeholders\n",
    "# \n",
    "# Need these for batch observations / actions / advantages in policy gradient loss function.\n",
    "#========================================================================================#\n",
    "\n",
    "sy_ob_no = tf.placeholder(shape=[None, ob_dim], name=\"ob\", dtype=tf.float32)\n",
    "if discrete:\n",
    "    sy_ac_na = tf.placeholder(shape=[None], name=\"ac\", dtype=tf.int32) \n",
    "else:\n",
    "    sy_ac_na = tf.placeholder(shape=[None, ac_dim], name=\"ac\", dtype=tf.float32) \n",
    "\n",
    "# Define a placeholder for advantages\n",
    "sy_adv_n = tf.placeholder(shape=[None], name=\"adv\", dtype=tf.float32)\n",
    "\n",
    "\n",
    "#========================================================================================#\n",
    "#                           ----------SECTION 4----------\n",
    "# Networks\n",
    "# \n",
    "# Make symbolic operations for\n",
    "#   1. Policy network outputs which describe the policy distribution.\n",
    "#       a. For the discrete case, just logits for each action.\n",
    "#\n",
    "#       b. For the continuous case, the mean / log std of a Gaussian distribution over \n",
    "#          actions.\n",
    "#\n",
    "#      Hint: use the 'build_mlp' function you defined in utilities.\n",
    "#\n",
    "#      Note: these ops should be functions of the placeholder 'sy_ob_no'\n",
    "#\n",
    "#   2. Producing samples stochastically from the policy distribution.\n",
    "#       a. For the discrete case, an op that takes in logits and produces actions.\n",
    "#\n",
    "#          Should have shape [None]\n",
    "#\n",
    "#       b. For the continuous case, use the reparameterization trick:\n",
    "#          The output from a Gaussian distribution with mean 'mu' and std 'sigma' is\n",
    "#\n",
    "#               mu + sigma * z,         z ~ N(0, I)\n",
    "#\n",
    "#          This reduces the problem to just sampling z. (Hint: use tf.random_normal!)\n",
    "#\n",
    "#          Should have shape [None, ac_dim]\n",
    "#\n",
    "#      Note: these ops should be functions of the policy network output ops.\n",
    "#\n",
    "#   3. Computing the log probability of a set of actions that were actually taken, \n",
    "#      according to the policy.\n",
    "#\n",
    "#      Note: these ops should be functions of the placeholder 'sy_ac_na', and the \n",
    "#      policy network output ops.\n",
    "#   \n",
    "#========================================================================================#\n",
    "\n",
    "if discrete:\n",
    "    # YOUR_CODE_HERE\n",
    "    sy_logits_na = build_mlp(sy_ob_no, ac_dim, \"nn\", size=size, n_layers=n_layers)\n",
    "    sy_sampled_ac = tf.reshape(tf.multinomial(tf.nn.log_softmax(sy_logits_na), tf.shape(sy_ob_no)[0]), [tf.shape(sy_ob_no)[0]]) # Hint: Use the tf.multinomial op\n",
    "    sy_logprob_n = tf.nn.softmax_cross_entropy_with_logits(logits = sy_logits_na, labels = tf.one_hot(sy_ac_na, ac_dim))\n",
    "#tf.gather_nd(tf.nn.log_softmax(sy_logits_na), tf.stack([tf.range(tf.shape(sy_logits_na)[0]), sy_ac_na],-1))\n",
    "\n",
    "else:\n",
    "    # YOUR_CODE_HERE\n",
    "    sy_mean = build_mlp(sy_ob_no, ac_dim, \"mean\", size=size, n_layers=n_layers)\n",
    "    sy_logstd = tf.log(tf.get_variable(name=\"stdev\", shape=[ac_dim, ac_dim])) # logstd should just be a trainable variable, not a network output.\n",
    "    sy_sampled_ac = tf.matmul(tf.random_normal([tf.shape(sy_ob_no)[0], ac_dim])+ sy_mean, sy_logstd)\n",
    "    sy_logprob_n = (-1/2)*tf.matmul(tf.matrix_inverse(sy_logstd), (sy_mean - sy_ac_na))  # Hint: Use the log probability under a multivariate gaussian. //still incorrect, todo\n",
    "\n",
    "\n",
    "\n",
    "#========================================================================================#\n",
    "#                           ----------SECTION 4----------\n",
    "# Loss Function and Training Operation\n",
    "#========================================================================================#\n",
    "\n",
    "loss = tf.reduce_mean(sy_logprob_n*sy_adv_n) # Loss function that we'll differentiate to get the policy gradient.\n",
    "update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "#========================================================================================#\n",
    "#                           ----------SECTION 5----------\n",
    "# Optional Baseline\n",
    "#========================================================================================#\n",
    "\n",
    "if nn_baseline:\n",
    "    baseline_prediction = tf.squeeze(build_mlp(\n",
    "                            sy_ob_no, \n",
    "                            1, \n",
    "                            \"nn_baseline\",\n",
    "                            n_layers=n_layers,\n",
    "                            size=size))\n",
    "    # Define placeholders for targets, a loss function and an update op for fitting a \n",
    "    # neural network baseline. These will be used to fit the neural network baseline. \n",
    "    # YOUR_CODE_HERE\n",
    "    baseline_update_op = TODO\n",
    "\n",
    "\n",
    "#========================================================================================#\n",
    "# Tensorflow Engineering: Config, Session, Variable initialization\n",
    "#========================================================================================#\n",
    "\n",
    "tf_config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1) \n",
    "\n",
    "sess = tf.Session(config=tf_config)\n",
    "sess.__enter__() # equivalent to `with sess:`\n",
    "tf.global_variables_initializer().run() #pylint: disable=E1101\n",
    "\n",
    "\n",
    "\n",
    "#========================================================================================#\n",
    "# Training Loop\n",
    "#========================================================================================#\n",
    "\n",
    "total_timesteps = 0\n",
    "\n",
    "for itr in range(n_iter):\n",
    "    print(\"********** Iteration %i ************\"%itr)\n",
    "\n",
    "    # Collect paths until we have enough timesteps\n",
    "    timesteps_this_batch = 0\n",
    "    paths = []\n",
    "    while True:\n",
    "        ob = env.reset()\n",
    "        obs, acs, rewards = [], [], []\n",
    "        animate_this_episode=(len(paths)==0 and (itr % 10 == 0) and animate)\n",
    "        steps = 0\n",
    "        while True:\n",
    "            if animate_this_episode:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "            obs.append(ob)\n",
    "            ac = sess.run(sy_sampled_ac, feed_dict={sy_ob_no : ob[None]})\n",
    "            ac = ac[0]\n",
    "            acs.append(ac)\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "                \n",
    "            rewards.append(rew)\n",
    "            steps += 1\n",
    "            if done or steps > max_path_length:\n",
    "                break\n",
    "        path = {\"observation\" : np.array(obs), \n",
    "                \"reward\" : np.array(rewards), \n",
    "                \"action\" : np.array(acs)}\n",
    "        paths.append(path)\n",
    "        timesteps_this_batch += pathlength(path)\n",
    "        if timesteps_this_batch > min_timesteps_per_batch:\n",
    "            break\n",
    "    total_timesteps += timesteps_this_batch\n",
    "\n",
    "    # Build arrays for observation, action for the policy gradient update by concatenating \n",
    "    # across paths\n",
    "    ob_no = np.concatenate([path[\"observation\"] for path in paths])\n",
    "    ac_na = np.concatenate([path[\"action\"] for path in paths])\n",
    "\n",
    "    #====================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Computing Q-values\n",
    "    #\n",
    "    # Your code should construct numpy arrays for Q-values which will be used to compute\n",
    "    # advantages (which will in turn be fed to the placeholder you defined above). \n",
    "    #\n",
    "    # Recall that the expression for the policy gradient PG is\n",
    "    #\n",
    "    #       PG = E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * (Q_t - b_t )]\n",
    "    #\n",
    "    # where \n",
    "    #\n",
    "    #       tau=(s_0, a_0, ...) is a trajectory,\n",
    "    #       Q_t is the Q-value at time t, Q^{pi}(s_t, a_t),\n",
    "    #       and b_t is a baseline which may depend on s_t. \n",
    "    #\n",
    "    # You will write code for two cases, controlled by the flag 'reward_to_go':\n",
    "    #\n",
    "    #   Case 1: trajectory-based PG \n",
    "    #\n",
    "    #       (reward_to_go = False)\n",
    "    #\n",
    "    #       Instead of Q^{pi}(s_t, a_t), we use the total discounted reward summed over \n",
    "    #       entire trajectory (regardless of which time step the Q-value should be for). \n",
    "    #\n",
    "    #       For this case, the policy gradient estimator is\n",
    "    #\n",
    "    #           E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * Ret(tau)]\n",
    "    #\n",
    "    #v       where\n",
    "    #\n",
    "    #           Ret(tau) = sum_{t'=0}^T gamma^t' r_{t'}.\n",
    "    #\n",
    "    #       Thus, you should compute\n",
    "    #\n",
    "    #           Q_t = Ret(tau)\n",
    "    #\n",
    "    #   Case 2: reward-to-go PG \n",
    "    #\n",
    "    #       (reward_to_go = True)\n",
    "    #\n",
    "    #       Here, you estimate Q^{pi}(s_t, a_t) by the discounted sum of rewards starting\n",
    "    #       from time step t. Thus, you should compute\n",
    "    #\n",
    "    #           Q_t = sum_{t'=t}^T gamma^(t'-t) * r_{t'}\n",
    "    #\n",
    "    #\n",
    "    # Store the Q-values for all timesteps and all trajectories in a variable 'q_n',\n",
    "    # like the 'ob_no' and 'ac_na' above. \n",
    "    #\n",
    "    #====================================================================================#\n",
    "\n",
    "    # YOUR_CODE_HERE\n",
    "    qs = []\n",
    "    if reward_to_go:\n",
    "        for l in range(len(paths)):\n",
    "            rewards = paths[l]['reward']\n",
    "            n_actions = rewards.shape[0]\n",
    "            q = np.zeros((n_actions))\n",
    "            for i in range(n_actions):\n",
    "                for j in range(n_actions-i):\n",
    "                    q[i] += rewards[i + j]*np.power(gamma, j)\n",
    "            qs.append(q)\n",
    "    else:\n",
    "        for l in range(len(paths)):\n",
    "            rewards = paths[l]['reward']\n",
    "            n_actions = rewards.shape[0]\n",
    "            q = np.zeros((n_actions))\n",
    "            for i in range(n_actions):\n",
    "                q += rewards[i]*np.power(gamma, i)\n",
    "            qs.append(q)\n",
    "    q_n = np.concatenate(qs)\n",
    "    #====================================================================================#\n",
    "    #                           ----------SECTION 5----------\n",
    "    # Computing Baselines\n",
    "    #====================================================================================#\n",
    "\n",
    "    if nn_baseline:\n",
    "        # If nn_baseline is True, use your neural network to predict reward-to-go\n",
    "        # at each timestep for each trajectory, and save the result in a variable 'b_n'\n",
    "        # like 'ob_no', 'ac_na', and 'q_n'.\n",
    "        #\n",
    "        # Hint #bl1: rescale the output from the nn_baseline to match the statistics\n",
    "        # (mean and std) of the current or previous batch of Q-values. (Goes with Hint\n",
    "        # #bl2 below.)\n",
    "\n",
    "        b_n = TODO\n",
    "        adv_n = q_n - b_n\n",
    "    else:\n",
    "        adv_n = q_n.copy()\n",
    "\n",
    "    #====================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Advantage Normalization\n",
    "    #====================================================================================#\n",
    "\n",
    "    if normalize_advantages:\n",
    "        # On the next line, implement a trick which is known empirically to reduce variance\n",
    "        # in policy gradient methods: normalize adv_n to have mean zero and std=1. \n",
    "        # YOUR_CODE_HERE\n",
    "        mean = np.mean(adv_n)\n",
    "        stdev = np.std(adv_n)\n",
    "        adv_n = (adv_n - mean)/stdev\n",
    "\n",
    "\n",
    "    #====================================================================================#\n",
    "    #                           ----------SECTION 5----------\n",
    "    # Optimizing Neural Network Baseline\n",
    "    #====================================================================================#\n",
    "    if nn_baseline:\n",
    "        # ----------SECTION 5----------\n",
    "        # If a neural network baseline is used, set up the targets and the inputs for the \n",
    "        # baseline. \n",
    "        # \n",
    "        # Fit it to the current batch in order to use for the next iteration. Use the \n",
    "        # baseline_update_op you defined earlier.\n",
    "        #\n",
    "        # Hint #bl2: Instead of trying to target raw Q-values directly, rescale the \n",
    "        # targets to have mean zero and std=1. (Goes with Hint #bl1 above.)\n",
    "\n",
    "        # YOUR_CODE_HERE\n",
    "        pass\n",
    "\n",
    "    #====================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Performing the Policy Update\n",
    "    #====================================================================================#\n",
    "\n",
    "    # Call the update operation necessary to perform the policy gradient update based on \n",
    "    # the current batch of rollouts.\n",
    "    # \n",
    "    # For debug purposes, you may wish to save the value of the loss function before\n",
    "    # and after an update, and then log them below. \n",
    "\n",
    "    # YOUR_CODE_HERE\n",
    "    sess.run(update_op, feed_dict={sy_ob_no : ob_no, sy_ac_na : ac_na, sy_adv_n : adv_n})\n",
    "\n",
    "    # Log diagnostics\n",
    "    returns = [path[\"reward\"].sum() for path in paths]\n",
    "    ep_lengths = [pathlength(path) for path in paths]\n",
    "    logz.log_tabular(\"Time\", time.time() - start)\n",
    "    logz.log_tabular(\"Iteration\", itr)\n",
    "    logz.log_tabular(\"AverageReturn\", np.mean(returns))\n",
    "    logz.log_tabular(\"StdReturn\", np.std(returns))\n",
    "    logz.log_tabular(\"MaxReturn\", np.max(returns))\n",
    "    logz.log_tabular(\"MinReturn\", np.min(returns))\n",
    "    logz.log_tabular(\"EpLenMean\", np.mean(ep_lengths))\n",
    "    logz.log_tabular(\"EpLenStd\", np.std(ep_lengths))\n",
    "    logz.log_tabular(\"TimestepsThisBatch\", timesteps_this_batch)\n",
    "    logz.log_tabular(\"TimestepsSoFar\", total_timesteps)\n",
    "    logz.dump_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 8.]\n"
     ]
    }
   ],
   "source": [
    "inp = tf.placeholder(dtype=tf.float32)\n",
    "ind = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "indexes = tf.stack([tf.range(tf.shape(inp)[0]), ind],-1)\n",
    "out = tf.gather_nd(inp, indexes)#tf.stack([tf.range(tf.shape(inp)[0]), ind],-1))\n",
    "\n",
    "sess = tf.Session()\n",
    "i = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "index = np.array([1,2,1], dtype = np.int32)\n",
    "o = sess.run(out, feed_dict = {inp : i, ind : index})\n",
    "print(o)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "out = tf.multinomial((np.softmaprob), 100)\n",
    "sess = tf.Session()\n",
    "\n",
    "p = np.array([[-5000000000, 1000000000]])\n",
    "o = sess.run(out, feed_dict = {prob : p})\n",
    "print(o)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
